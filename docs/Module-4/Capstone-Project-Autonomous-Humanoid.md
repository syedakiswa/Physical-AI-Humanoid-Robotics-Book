# Capstone Project – The Autonomous Humanoid

In this final project, students build a system where a simulated humanoid robot:

### 1. **Receives a voice command**

Example commands:
- “Pick the bottle”
- “Navigate to the kitchen”
- “Move the chair”
- “Clean the room”

### 2. **Performs Cognitive Planning**

LLM breaks the voice instruction into steps.

### 3. **Navigates the Environment**

- Uses Nav2
- Avoids obstacles
- Walks like a humanoid

### 4. **Detects Objects Using Vision**

- Identifies target object (color, shape, location)
- Filters other items
- Confirms object visibility

### 5. **Manipulates the Object**

- Approaches object
- Picks it up
- Places it at the requested destination

### Outcome:

A fully autonomous humanoid robot that performs real tasks using:

- Voice  
- Language  
- Vision  
- Navigation  
- Manipulation  

This is the complete **VLA → Robot Action** pipeline in one demo.
